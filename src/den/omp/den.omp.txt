Zach North
603 885 768

My OpenMP implementation is fairly straightforward: I simply invoked a
parallel for loop over the main loop in the sequential function.

One thing that I did change was the Converged check -- I changed it to use
a pointer instead of an int. This was so the seperate threads could share
the pointer and then check for convergence inside their respective control --
if they found an instance of the algorithm not converging, they could change the
Convergence variable without using a break statement.

The fact that I was able to perform nearly every calculation inside OpenMP threads
caused this function to be quite performant. I estimate it was roughly 2x as fast
as the sequential code, although at my time of writing this report the servers
are under heavy load and the numbers are not very accurate.

To speed this function up I would look at parallelizing the g loop -- the one that
initializes the g array. I couldn't get this to work but it is a large, O(N*M) 
loop that is being run sequentially. If it could be split up the function would
as a whole run much faster.

To speed it up further, I would probably look at splitting up the u array to 
avoid parallel memory accesses -- perhaps using more memory in order to copy
pieces of it around for seperate threads. But, this can lead to problems because
it accesses data "UP", "DOWN", etc. The iterations on the "overlap" would
still have to wait on each other.

Some sample numbers:
Time with sequential implementation:

real    0m0.669s
user    0m0.659s
sys 0m0.002s

Time with OpenMP implementation:
real   0m0.662s
user   0m0.651s
sys    0m0.019s

This was during a period of heavy server load, however, so I take those
numbers with a grain of salt. Generally the OpenMP code was running faster
than the sequential implementation.

